{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Modules\n",
        "\n",
        "Resource: [TensorFlow Guide](https://www.tensorflow.org/guide/intro_to_modules)"
      ],
      "metadata": {
        "id": "OT5PW8wHkF2X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most models are made of layers. Layers are functions with a known mathematical structure that can be reused and have trainable variables. In TensorFlow, most high-level implementations of layers and models, such as Keras or Sonnet, are built on the same foundational class: tf.Module."
      ],
      "metadata": {
        "id": "zPVeNsKPoPxG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dM7VaTKdgy0y"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from datetime import datetime\n",
        "\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Modules\n",
        "\n",
        "### Build a simple module\n",
        "\n",
        "Modules and, by extension, layers are deep-learning terminology for \"objects\": they have internal state, and methods that use that state."
      ],
      "metadata": {
        "id": "AE6iCiXVoQ9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleModule(tf.Module):\n",
        "  def __init__(self, name = None):\n",
        "    super().__init__(name = name)\n",
        "    self.a_variable = tf.Variable(5.0, name = \"train_me\")\n",
        "    self.non_trainable_variable = tf.Variable(5.0,\n",
        "                                              trainable = False,\n",
        "                                              name = \"do_not_train_me\")\n",
        "\n",
        "  def __call__(self, x):\n",
        "    return self.a_variable * x + self.non_trainable_variable"
      ],
      "metadata": {
        "id": "CqG9uw4CoQRc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simple_module = SimpleModule(name = \"simple\")\n",
        "simple_module(tf.constant(5.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0fIemYBpBXd",
        "outputId": "851057e9-d492-4f04-fdb0-24ea8eb69457"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=30.0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting all variables from the module\n",
        "\n",
        "By subclassing tf.Module, any tf.Variable or tf.Module instances assigned to this object's properties are automatically collected. This allows you to save and load variables, and also create collections of tf.Module(s)."
      ],
      "metadata": {
        "id": "Yl96ewbopV8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simple_module.variables"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WvN5vqKpQZE",
        "outputId": "780bf3da-4d65-4c3d-afac-93d87ad744eb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Variable 'train_me:0' shape=() dtype=float32, numpy=5.0>,\n",
              " <tf.Variable 'do_not_train_me:0' shape=() dtype=float32, numpy=5.0>)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simple_module.trainable_variables"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzCCHKzRpS0D",
        "outputId": "2a47d776-069d-4bcb-ac5e-747330dba532"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Variable 'train_me:0' shape=() dtype=float32, numpy=5.0>,)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simple_module.non_trainable_variables"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXZYNeiUph5b",
        "outputId": "d17adb9a-1e3c-4535-bd9d-5b7d8d55b1d2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Variable 'do_not_train_me:0' shape=() dtype=float32, numpy=5.0>,)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementing a model with dense layers"
      ],
      "metadata": {
        "id": "JUMhynG4pof6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define dense layer\n",
        "class Dense(tf.Module):\n",
        "  def __init__(self, in_features, out_features, name = None):\n",
        "    super().__init__(name = name)\n",
        "    self.w = tf.Variable(\n",
        "        tf.random.normal([in_features, out_features]),\n",
        "                         name = \"w\")\n",
        "    self.b = tf.Variable(tf.random.normal([out_features]), name = \"b\")\n",
        "\n",
        "  def __call__(self, x):\n",
        "    y = tf.matmul(x, self.w) + self.b\n",
        "    return tf.nn.relu(y)"
      ],
      "metadata": {
        "id": "hhp9Jo4wpmbG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define model architecture\n",
        "class SequentialModule(tf.Module):\n",
        "  def __init__(self, in_features, out_features, name = None):\n",
        "    super().__init__(name = name)\n",
        "\n",
        "    self.dense_1 = Dense(in_features = in_features, out_features = 10)\n",
        "    self.dense_2 = Dense(in_features = 10, out_features = out_features)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    x = self.dense_1(x)\n",
        "    return self.dense_2(x)"
      ],
      "metadata": {
        "id": "5Za9LsT9qODv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model = SequentialModule(3, 1, \"My_Model\")\n",
        "print(\"Model results:\", test_model(tf.constant([[2.0, 2.0, 2.0]])).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEJvgr2oq4PR",
        "outputId": "8ee41433-689b-498f-c1b8-bc23d8d650b1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model results: [[10.9452305]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_model = SequentialModule(3, 5, \"My_Model\")\n",
        "print(\"Model results:\", my_model(tf.constant([[-3.0, 2.0, 12.0]])).numpy())\n",
        "print(\"Model results:\", my_model(tf.constant([[3.0, 12.0, 2.0]])).numpy())\n",
        "print(\"Model results:\", my_model(tf.constant([[-3.0, 2.0, 2.0]])).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7zoyS2Qq-rl",
        "outputId": "31909f13-e406-4f65-a56c-9ce9d6af966f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model results: [[35.862324  0.        0.       14.323252 24.277296]]\n",
            "Model results: [[15.760409   0.         0.         2.4547026  7.96459  ]]\n",
            "Model results: [[ 5.720687  0.        0.       10.972248 13.360544]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accessing submodules and variables within a module\n",
        "\n",
        "tf.Module instances will automatically collect, recursively, any tf.Variable or tf.Module instances assigned to it. This allows you to manage collections of tf.Modules with a single model instance, and save and load whole models."
      ],
      "metadata": {
        "id": "1Sc-qhIzsEzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for submodule in my_model.submodules:\n",
        "  print(\"Submodule:\", submodule)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruxPwgd5rwKM",
        "outputId": "bd58326f-3381-49ea-a4f2-08fac8665399"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submodule: <__main__.Dense object at 0x7fc9ee3a04c0>\n",
            "Submodule: <__main__.Dense object at 0x7fc9ee36ece0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for var in my_model.variables:\n",
        "  print(var, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTl41_fcrO5l",
        "outputId": "b201d50c-cf5d-4f73-d8cc-9f5a308ee961"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.Variable 'b:0' shape=(10,) dtype=float32, numpy=\n",
            "array([ 0.4391686 ,  0.49363697,  0.08814096,  1.1443    , -0.7472049 ,\n",
            "       -0.67132956,  0.13753696, -0.5086929 , -0.3485612 ,  0.5009082 ],\n",
            "      dtype=float32)> \n",
            "\n",
            "<tf.Variable 'w:0' shape=(3, 10) dtype=float32, numpy=\n",
            "array([[-0.47020775, -1.3438826 , -0.27380255, -0.23510106,  0.8166703 ,\n",
            "         0.43490455, -0.23481819, -0.9769432 ,  0.98039985,  1.0066903 ],\n",
            "       [-0.05855056, -0.51440233,  0.17947087,  0.6514524 ,  0.12257692,\n",
            "        -0.27936143,  0.02550284, -0.94399124, -0.21225931, -1.015371  ],\n",
            "       [-0.30464157,  0.34900215,  0.4863775 ,  0.9624898 ,  1.0194541 ,\n",
            "        -0.22768553, -0.79427147,  0.48206282,  0.11618549, -0.27889112]],\n",
            "      dtype=float32)> \n",
            "\n",
            "<tf.Variable 'b:0' shape=(5,) dtype=float32, numpy=\n",
            "array([-0.3733548, -1.454579 ,  1.7649133,  0.4787972,  0.68699  ],\n",
            "      dtype=float32)> \n",
            "\n",
            "<tf.Variable 'w:0' shape=(10, 5) dtype=float32, numpy=\n",
            "array([[-0.09249494,  1.7658429 , -0.5362403 , -0.79304516,  1.5821401 ],\n",
            "       [ 0.73336804,  0.6341062 , -0.17568077,  1.3870931 ,  0.93722224],\n",
            "       [ 0.23415203, -1.8091453 ,  0.01572109,  0.76686805,  0.999417  ],\n",
            "       [ 0.36464947, -0.23124813, -1.1446471 ,  0.73846436,  0.7866054 ],\n",
            "       [ 2.2012763 , -1.4059587 , -1.0475123 , -1.4581368 , -0.5776009 ],\n",
            "       [-1.9554378 , -1.8608603 , -0.687965  ,  0.4980102 , -1.1247591 ],\n",
            "       [ 1.0692483 ,  0.5518842 , -0.233129  , -2.2947164 , -0.6942215 ],\n",
            "       [ 0.4976076 , -0.36482203,  0.3529977 ,  0.06536932,  0.48794857],\n",
            "       [ 1.3901111 , -1.6639835 ,  1.1701119 ,  0.8017935 , -0.4032758 ],\n",
            "       [ 1.3903214 ,  0.6040666 ,  1.8876342 ,  2.0214474 , -0.3634293 ]],\n",
            "      dtype=float32)> \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deffering to create variables\n",
        "\n",
        "By deferring variable creation to the first time the module is called with a specific input shape, you do not need specify the input size up front.\n",
        "\n",
        "This flexibility is why TensorFlow layers often only need to specify the shape of their outputs, such as in tf.keras.layers.Dense, rather than both the input and output size."
      ],
      "metadata": {
        "id": "42x_ltAWssqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FlexibleDense(tf.Module):\n",
        "  def __init__(self, out_features, name = None):\n",
        "    super().__init__(name = name)\n",
        "    self.is_built = False\n",
        "    self.out_features = out_features\n",
        "\n",
        "  def __call__(self, x):\n",
        "    if not self.is_built:\n",
        "      self.w = tf.Variable(\n",
        "          tf.random.normal([x.shape[-1], self.out_features]),\n",
        "          name = \"w\"\n",
        "      )\n",
        "      self.b = tf.Variable(tf.zeros([self.out_features]), name = \"b\")\n",
        "      self.is_built = True\n",
        "\n",
        "    y = tf.matmul(x, self.w) + self.b\n",
        "    return tf.nn.relu(y)"
      ],
      "metadata": {
        "id": "ITB1UVXDsEEs"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FlexibleSequential(tf.Module):\n",
        "  def __init__(self, out_features, name = None):\n",
        "    super().__init__(name = name)\n",
        "    self.dense_1 = FlexibleDense(out_features = 3)\n",
        "    self.dense_2 = FlexibleDense(out_features = out_features)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    x = self.dense_1(x)\n",
        "    return self.dense_2(x)"
      ],
      "metadata": {
        "id": "_fBzgwnYtsrZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = FlexibleSequential(3, name = \"the_model\")\n",
        "new_model(tf.constant([[1.39, 4.22, .23, .42, .76, .34, 5.43]])).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiWRHjSbuHc9",
        "outputId": "ab3d7e81-4f34-4676-898c-2bbaf3bd7441"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.0002193, 0.       , 6.246097 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving Weights"
      ],
      "metadata": {
        "id": "R4BDxEWhvXk2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving as a checkpoint\n",
        "\n",
        "Checkpoints are just the weights (that is, the values of the set of variables inside the module and its submodules).\n",
        "\n",
        "Checkpoints consist of two kinds of files: the data itself and an index file for metadata. The index file keeps track of what is actually saved and the numbering of checkpoints, while the checkpoint data contains the variable values and their attribute lookup paths.\n",
        "\n"
      ],
      "metadata": {
        "id": "O2aUd-qfvcV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_model = FlexibleSequential(3, name = \"the_model\")\n",
        "my_model(tf.constant([[2.39, 4.22, .23, .42, .76, .34, 5.43]])).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UH0yL8fOxZcY",
        "outputId": "1bfebf95-179c-472f-baa3-5e563da857c4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.      , 12.247864,  4.819643]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chkp_path = \"./my_checkpoint/checkpoint\"\n",
        "checkpoint = tf.train.Checkpoint(model=my_model)\n",
        "checkpoint.write(chkp_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "OWoxbx7mvGn9",
        "outputId": "e1b11612-0bf5-4d1d-e6bd-dde7455a3a40"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./my_checkpoint/checkpoint'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can look inside a checkpoint to be sure the whole collection of variables is saved, sorted by the Python object that contains them."
      ],
      "metadata": {
        "id": "q90mP5WVwYmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.train.list_variables(chkp_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff4-nuNfvkrt",
        "outputId": "731c635d-7c33-489d-845c-2cb641ca1554"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('_CHECKPOINTABLE_OBJECT_GRAPH', []),\n",
              " ('model/dense_1/b/.ATTRIBUTES/VARIABLE_VALUE', [3]),\n",
              " ('model/dense_1/w/.ATTRIBUTES/VARIABLE_VALUE', [7, 3]),\n",
              " ('model/dense_2/b/.ATTRIBUTES/VARIABLE_VALUE', [3]),\n",
              " ('model/dense_2/w/.ATTRIBUTES/VARIABLE_VALUE', [3, 3])]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = FlexibleSequential(3)\n",
        "new_checkpoint = tf.train.Checkpoint(model = new_model)\n",
        "new_checkpoint.restore(chkp_path)\n",
        "\n",
        "new_model(tf.constant([[2.39, 4.22, .23, .42, .76, .34, 5.43]])).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lo09hgU-wVR2",
        "outputId": "5681329c-dfb1-4fdb-c4ad-38c7a7e5fd59"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.      , 12.247864,  4.819643]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving functions\n",
        "\n",
        "TensorFlow can run models without the original Python objects, as demonstrated by TensorFlow Serving and TensorFlow Lite, even when you download a trained model from TensorFlow Hub.\n",
        "\n",
        "TensorFlow needs to know how to do the computations described in Python, but without the original code. To do this, you can make a graph, which is described in the Introduction to graphs and functions guide.\n",
        "\n",
        "This graph contains operations, or ops, that implement the function.\n",
        "\n",
        "You can define a graph in the model above by adding the @tf.function decorator to indicate that this code should run as a graph."
      ],
      "metadata": {
        "id": "XEhHfogCyEfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FlexibleSequential(tf.Module):\n",
        "  def __init__(self, out_features, name = None):\n",
        "    super().__init__(name = name)\n",
        "    self.dense_1 = FlexibleDense(out_features = 3)\n",
        "    self.dense_2 = FlexibleDense(out_features = out_features)\n",
        "\n",
        "  @tf.function\n",
        "  def __call__(self, x):\n",
        "    x = self.dense_1(x)\n",
        "    return self.dense_2(x)"
      ],
      "metadata": {
        "id": "vwzYscmoxIyG"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_model = FlexibleSequential(3)\n",
        "print(my_model(tf.constant([[1., 2., 1., 3., 1., 2., 1.]])))\n",
        "print(my_model([[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]]))\n",
        "print(my_model([\n",
        " [[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0],\n",
        "  [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]]]\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HGgbQuMyTx6",
        "outputId": "30649b8f-bf59-4aaa-c0ec-abbc66afb2f2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[ 0.      31.62707  0.     ]], shape=(1, 3), dtype=float32)\n",
            "tf.Tensor([[ 0.       31.389559  0.      ]], shape=(1, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[ 0.       31.389559  0.      ]\n",
            "  [ 0.       31.389559  0.      ]]], shape=(1, 2, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving a SavedModel\n",
        "\n",
        "The recommended way of sharing completely trained models is to use SavedModel. SavedModel contains both a collection of functions and a collection of weights."
      ],
      "metadata": {
        "id": "RRIOsbTIy7qi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(my_model, \"my_model\")"
      ],
      "metadata": {
        "id": "i35oU3rxyYCO"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = tf.saved_model.load(\"my_model\")"
      ],
      "metadata": {
        "id": "pcQullgezc4w"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(new_model(tf.constant([[1., 2., 1., 3., 1., 2., 1.]])))\n",
        "print(new_model([[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]]))\n",
        "print(new_model([\n",
        " [[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0],\n",
        "  [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]]]\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkaRgdCAztuu",
        "outputId": "fb506ecf-489f-4cb9-8c1d-6942ae81114c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[ 0.      31.62707  0.     ]], shape=(1, 3), dtype=float32)\n",
            "tf.Tensor([[ 0.       31.389559  0.      ]], shape=(1, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[ 0.       31.389559  0.      ]\n",
            "  [ 0.       31.389559  0.      ]]], shape=(1, 2, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(new_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIhVlCkf0Ac9",
        "outputId": "ff247272-8d3a-4636-faed-ee322cfc7976"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Keras Models and Layers\n",
        "\n",
        "You can build your own high-level API on top of tf.Module, and people have. Keras layers and models have a lot more extra features. hese features allow for far more complex models through subclassing, such as a custom GAN or a Variational AutoEncoder (VAE) model. Keras models also come with extra functionality that makes them easy to train, evaluate, load, save, and even train on multiple machines."
      ],
      "metadata": {
        "id": "0U6wQoAS00CD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inheriting from keras layers\n",
        "\n",
        "You can convert a module into a Keras layer just by swapping out the parent and then changing __call__ to call."
      ],
      "metadata": {
        "id": "i4nW6AFR13Nl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDense(tf.keras.layers.Layer):\n",
        "  # Adding **kwargs to support base Keras layer arguments\n",
        "  def __init__(self, in_features, out_features, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "\n",
        "    # This will soon move to the build step; see below\n",
        "    self.w = tf.Variable(\n",
        "      tf.random.normal([in_features, out_features]), name='w')\n",
        "    self.b = tf.Variable(tf.zeros([out_features]), name='b')\n",
        "  def call(self, x):\n",
        "    y = tf.matmul(x, self.w) + self.b\n",
        "    return tf.nn.relu(y)\n",
        "\n",
        "simple_layer = MyDense(name=\"simple\", in_features=3, out_features=3)"
      ],
      "metadata": {
        "id": "7eb_P8QP0Eqv"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simple_layer([[2.0, 2.0, 2.0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ie42wKg2Al3",
        "outputId": "73c43da9-aefd-4d22-a346-ef1622cd7af7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[0.      , 0.      , 3.446586]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utilising the build method\n",
        "\n",
        "It's convenient in many cases to wait to create variables until you are sure of the input shape. Keras layers come with an extra lifecycle step that allows you more flexibility in how you define your layers. This is defined in the build function. build is called exactly once, and it is called with the shape of the input. It's usually used to create variables (weights)."
      ],
      "metadata": {
        "id": "yQlqY_X42Inv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FlexibleDense(tf.keras.layers.Layer):\n",
        "  # Note the added `**kwargs`, as Keras supports many arguments\n",
        "  def __init__(self, out_features, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.out_features = out_features\n",
        "\n",
        "  def build(self, input_shape):  # Create the state of the layer (weights)\n",
        "    self.w = tf.Variable(\n",
        "      tf.random.normal([input_shape[-1], self.out_features]), name='w')\n",
        "    self.b = tf.Variable(tf.zeros([self.out_features]), name='b')\n",
        "\n",
        "  def call(self, inputs):  # Defines the computation from inputs to outputs\n",
        "    return tf.matmul(inputs, self.w) + self.b"
      ],
      "metadata": {
        "id": "YA3SFM5o2A6F"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the instance of the layer\n",
        "flexible_dense = FlexibleDense(out_features=3)"
      ],
      "metadata": {
        "id": "KXn4Q47H2U8x"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flexible_dense.variables"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7Cxyrks2RRG",
        "outputId": "f923ea34-90c8-449f-c347-476e29eb71e9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since build is only called once, inputs will be rejected if the input shape is not compatible with the layer's variables:"
      ],
      "metadata": {
        "id": "L7owoZ4Z2c8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  print(\"Model results:\", flexible_dense(tf.constant([[2.0, 2.0, 2.0, 2.0]])))\n",
        "except tf.errors.InvalidArgumentError as e:\n",
        "  print(\"Failed:\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BXoZWpd2Txu",
        "outputId": "0ec9df6f-a549-4e2a-f3ee-4ebf847884d7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model results: tf.Tensor([[4.4299755 6.7267056 4.680213 ]], shape=(1, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Keras models\n",
        "\n",
        "Keras also provides a full-featured model class called tf.keras.Model. It inherits from tf.keras.layers.Layer, so a Keras model can be used and nested in the same way as Keras layers. Keras models come with extra functionality that makes them easy to train, evaluate, load, save, and even train on multiple machines.\n",
        "\n",
        "You can define the SequentialModule from above with nearly identical code, again converting __call__ to call() and changing the parent"
      ],
      "metadata": {
        "id": "_AC5kjsZ2g0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FlexibleSequential(tf.keras.Model):\n",
        "  def __init__(self, name=None, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.dense_1 = FlexibleDense(out_features=3)\n",
        "    self.dense_2 = FlexibleDense(out_features=2)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.dense_1(x)\n",
        "    return self.dense_2(x)\n",
        "\n",
        "# You have made a Keras model!\n",
        "my_sequential_model = FlexibleSequential(name=\"the_model\")\n",
        "\n",
        "# Call it on a tensor, with random results\n",
        "print(\"Model results:\", my_sequential_model(tf.constant([[2.0, 2.0, 2.0]])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdbkOYH52Yp-",
        "outputId": "aaea36d7-24f9-4c6e-d354-8bfc6375b5b0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model results: tf.Tensor([[ 6.0421724 -0.2327581]], shape=(1, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_sequential_model.submodules"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBA2QNl5280w",
        "outputId": "67f4a075-fd67-441b-9a7e-00fd075468ca"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<__main__.FlexibleDense at 0x7fc9ee3a1360>,\n",
              " <__main__.FlexibleDense at 0x7fc9eb269030>)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_sequential_model.variables"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKoYXcPM2Xan",
        "outputId": "44e99c12-de22-4fb2-8b34-45c552e00837"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'flexible_sequential/flexible_dense_1/w:0' shape=(3, 3) dtype=float32, numpy=\n",
              " array([[-1.6878377 ,  0.46307197,  0.39740363],\n",
              "        [ 1.5902584 ,  1.1351705 , -0.52632105],\n",
              "        [ 1.5269663 , -1.0764346 , -0.50975937]], dtype=float32)>,\n",
              " <tf.Variable 'flexible_sequential/flexible_dense_1/b:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>,\n",
              " <tf.Variable 'flexible_sequential/flexible_dense_2/w:0' shape=(3, 2) dtype=float32, numpy=\n",
              " array([[ 1.6678193 , -0.5416872 ],\n",
              "        [ 0.54136133,  0.37101912],\n",
              "        [-0.5552739 , -0.72697324]], dtype=float32)>,\n",
              " <tf.Variable 'flexible_sequential/flexible_dense_2/b:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Functional API to build a model\n",
        "\n",
        "If you are constructing models that are simple assemblages of existing layers and inputs, you can save time and space by using the functional API, which comes with additional features around model reconstruction and architecture.\n",
        "\n",
        "The major difference here is that the input shape is specified up front as part of the functional construction process. The input_shape argument in this case does not have to be completely specified; you can leave some dimensions as None."
      ],
      "metadata": {
        "id": "4xTKGf8e3Wpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.Input(shape=[3,])\n",
        "\n",
        "x = FlexibleDense(3)(inputs)\n",
        "x = FlexibleDense(2)(x)\n",
        "\n",
        "my_functional_model = tf.keras.Model(inputs=inputs, outputs=x)\n",
        "\n",
        "my_functional_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmnUJlms28eC",
        "outputId": "9cc2b8df-7ea2-4511-dd58-e4dcd8b56a10"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 3)]               0         \n",
            "                                                                 \n",
            " flexible_dense_3 (FlexibleD  (None, 3)                12        \n",
            " ense)                                                           \n",
            "                                                                 \n",
            " flexible_dense_4 (FlexibleD  (None, 2)                8         \n",
            " ense)                                                           \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20\n",
            "Trainable params: 20\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}